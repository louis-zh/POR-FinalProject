{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HI8CoOMMDorP","executionInfo":{"status":"ok","timestamp":1714514908207,"user_tz":240,"elapsed":195,"user":{"displayName":"Louis Zheng","userId":"12995729217381681319"}},"outputId":"14468243-1185-4f36-b41d-6b60acd1b110"},"outputs":[{"output_type":"stream","name":"stdout","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2023 NVIDIA Corporation\n","Built on Tue_Aug_15_22:02:13_PDT_2023\n","Cuda compilation tools, release 12.2, V12.2.140\n","Build cuda_12.2.r12.2/compiler.33191640_0\n"]}],"source":["# make sure CUDA is installed\n","!nvcc --version"]},{"cell_type":"code","source":["# make sure you have a GPU runtime (if this fails go to runtime -> change runtime type)\n","!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SYf76JKUDu6N","executionInfo":{"status":"ok","timestamp":1714514908454,"user_tz":240,"elapsed":250,"user":{"displayName":"Louis Zheng","userId":"12995729217381681319"}},"outputId":"70ba6490-e4c2-42be-90b6-fb205774f2b3"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Apr 30 22:08:28 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   53C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["# CUDA in Jupyter helpers\n","!pip install nvcc4jupyter\n","%load_ext nvcc4jupyter\n","# to learn about how to do more fancy things with CUDA using this API see:\n","# https://nvcc4jupyter.readthedocs.io/en/latest/index.html"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SJqb_K0JDxbI","executionInfo":{"status":"ok","timestamp":1714514920330,"user_tz":240,"elapsed":11879,"user":{"displayName":"Louis Zheng","userId":"12995729217381681319"}},"outputId":"fdc11ea0-4d59-449a-a880-d30ac0595aa5"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting nvcc4jupyter\n","  Downloading nvcc4jupyter-1.2.1-py3-none-any.whl (10 kB)\n","Installing collected packages: nvcc4jupyter\n","Successfully installed nvcc4jupyter-1.2.1\n","Detected platform \"Colab\". Running its setup...\n","Source files will be saved in \"/tmp/tmphvrcf9ub\".\n"]}]},{"cell_type":"markdown","source":["# Block-Thomas for size n matrix\n","\n","The Block size $m$ is currently only supported to be 2. We hope to supported varying value in the future through more complex implementations of matrix multiplication and inversion.\n","\n","For testing purposes, the input Block-Tridigaonal system is fixed."],"metadata":{"id":"ElUQ5A4nlyxK"}},{"cell_type":"code","source":["%%cuda\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <string.h>\n","#include <time.h>\n","#include <cuda_runtime.h>\n","\n","__device__\n","void matrixMultiply(double *A, double *B, double *C, int m, int k, int n) {\n","    for (int i = 0; i < m; i++) {\n","        for (int j = 0; j < n; j++) {\n","            C[i * n + j] = 0;\n","            for (int x = 0; x < k; x++) {\n","                C[i * n + j] += A[i * k + x] * B[x * n + j];\n","            }\n","        }\n","    }\n","}\n","\n","__device__\n","void matrixSubtract(double *A, double *B, double *C, int m, int n) {\n","    for (int row = 0; row < m; row++) {\n","        for (int col = 0; col < n; col++) {\n","            C[row * n + col] = A[row * n + col] - B[row * n + col];\n","        }\n","    }\n","}\n","\n","__device__\n","void invertMatrix(double *mat, double *invMat, int n) {\n","    // This simple inversion is appropriate only for 2x2 matrices\n","    double a = mat[0], b = mat[1], c = mat[2], d = mat[3];\n","    double det = a * d - b * c;\n","    if (det == 0) {\n","        printf(\"Matrix is singular and cannot be inverted.\\n\");\n","        return;\n","    }\n","    double invDet = 1.0 / det;\n","    invMat[0] =  d * invDet;\n","    invMat[1] = -b * invDet;\n","    invMat[2] = -c * invDet;\n","    invMat[3] =  a * invDet;\n","}\n","\n","__global__\n","void blockTridiagonalSolver(double *a, double *b, double *c, double *d, double *x, int N, int blockSize) {\n","    int idx = threadIdx.x + blockIdx.x * blockDim.x;\n","    if (idx != 0) return;  // Ensure only one thread does the work\n","\n","    int matSize = blockSize * blockSize;\n","    int vecSize = blockSize;  // Simplified vector size handling\n","    double *cp = (double *)malloc((N-1) * matSize * sizeof(double));\n","    double *dp = (double *)malloc(N * vecSize * sizeof(double));\n","    double *A_inv = (double *)malloc(matSize * sizeof(double));\n","    double *temp = (double *)malloc(matSize * sizeof(double));\n","\n","    // First transformation using b[0]\n","    invertMatrix(b, A_inv, blockSize);\n","    matrixMultiply(A_inv, c, cp, blockSize, blockSize, blockSize);\n","    matrixMultiply(A_inv, d, dp, blockSize, blockSize, 1);\n","\n","    // Forward sweep\n","    for (int i = 1; i < N; i++) {\n","        matrixMultiply(a + (i-1) * matSize, cp + (i-1) * matSize, temp, blockSize, blockSize, blockSize);\n","        matrixSubtract(b + i * matSize, temp, temp, blockSize, blockSize);\n","        invertMatrix(temp, A_inv, blockSize);\n","        if (i < N-1) {\n","            matrixMultiply(A_inv, c + i * matSize, cp + i * matSize, blockSize, blockSize, blockSize);\n","        }\n","        matrixMultiply(a + (i-1) * matSize, dp + (i-1) * vecSize, temp, blockSize, blockSize, 1);\n","        matrixSubtract(d + i * vecSize, temp, temp, blockSize, 1);\n","        matrixMultiply(A_inv, temp, dp + i * vecSize, blockSize, blockSize, 1);\n","    }\n","\n","    // Backward substitution\n","    memcpy(x + (N-1) * vecSize, dp + (N-1) * vecSize, vecSize * sizeof(double));\n","    for (int i = N-2; i >= 0; i--) {\n","        matrixMultiply(cp + i * matSize, x + (i+1) * vecSize, temp, blockSize, blockSize, 1);\n","        matrixSubtract(dp + i * vecSize, temp, x + i * vecSize, blockSize, 1);\n","    }\n","\n","    free(cp);\n","    free(dp);\n","    free(A_inv);\n","    free(temp);\n","}\n","\n","__host__\n","int main() {\n","    const int N = 3;\n","    const int blockSize = 2;\n","\n","    double h_X[N * blockSize];\n","    double h_B[N * blockSize * blockSize] = {4, 1, 1, 3, 5, 2, 2, 4, 6, 1, 1, 5};\n","    double h_C[(N-1) * blockSize * blockSize] = {-1, 0, 0, -1, -1, 0, 0, -1};\n","    double h_A[(N-1) * blockSize * blockSize] = {-2, 0, 0, -2, -2, 0, 0, -2};\n","    double h_D[N * blockSize] = {1, 2, 3, 4, 5, 6};\n","\n","    // Device memory pointers\n","    double *d_A, *d_B, *d_C, *d_D, *d_X;\n","\n","    // Allocate memory on the device\n","    cudaMalloc(&d_A, sizeof(h_A));\n","    cudaMalloc(&d_B, sizeof(h_B));\n","    cudaMalloc(&d_C, sizeof(h_C));\n","    cudaMalloc(&d_D, sizeof(h_D));\n","    cudaMalloc(&d_X, N * blockSize * sizeof(double));\n","\n","    // Copy data from host to device\n","    cudaMemcpy(d_A, h_A, sizeof(h_A), cudaMemcpyHostToDevice);\n","    cudaMemcpy(d_B, h_B, sizeof(h_B), cudaMemcpyHostToDevice);\n","    cudaMemcpy(d_C, h_C, sizeof(h_C), cudaMemcpyHostToDevice);\n","    cudaMemcpy(d_D, h_D, sizeof(h_D), cudaMemcpyHostToDevice);\n","\n","    // Launch kernel with a single thread\n","    blockTridiagonalSolver<<<1, 1>>>(d_A, d_B, d_C, d_D, d_X, N, blockSize);\n","\n","    // Copy result back to host\n","    cudaMemcpy(h_X, d_X, N * blockSize * sizeof(double), cudaMemcpyDeviceToHost);\n","\n","    // Print solution\n","    printf(\"Solution X:\\n\");\n","    for (int i = 0; i < N; i++) {\n","        for (int j = 0; j < blockSize; j++) {\n","            printf(\"%f \", h_X[i * blockSize + j]);\n","        }\n","        printf(\"\\n\");\n","    }\n","\n","    // Free device memory\n","    cudaFree(d_A);\n","    cudaFree(d_B);\n","    cudaFree(d_C);\n","    cudaFree(d_D);\n","    cudaFree(d_X);\n","\n","    return 0;\n","}\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LuNbBvV2B6Ke","executionInfo":{"status":"ok","timestamp":1714515099607,"user_tz":240,"elapsed":1889,"user":{"displayName":"Louis Zheng","userId":"12995729217381681319"}},"outputId":"17cad103-e05f-4adc-cc66-429d72a35074"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Solution X:\n","-0.280957 1.629456 \n","-0.494371 2.607411 \n","0.304878 2.181989 \n","\n"]}]}]}